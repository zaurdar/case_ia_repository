{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXIxwaKiPk8E",
        "outputId": "1d20fb5a-6e24-44f1-a394-55db9ace198e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.237-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.237-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.237 ultralytics-thop-2.0.18\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh3OV82vd3RL",
        "outputId": "4835dd13-525c-437e-e793-817b5a7c7195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.237 ðŸš€ Python-3.12.12 torch-2.9.0+cpu CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 21.1/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_s3WUqFeHoh"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tasLwe5ePYo",
        "outputId": "afda868e-f3e9-4867-fea2-cae73af720be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 77.2MB/s 0.1s\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolov8n.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTlJ8G-6YhZI",
        "outputId": "453af0ca-3954-4afa-b865-2b862746a235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepGaze'...\n",
            "remote: Enumerating objects: 142, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 142 (delta 7), reused 2 (delta 2), pack-reused 132 (from 1)\u001b[K\n",
            "Receiving objects: 100% (142/142), 892.66 KiB | 10.38 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/matthias-k/DeepGaze\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uw7N19LdLkk",
        "outputId": "116c88e8-c6f6-4be6-8643-20c992131233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-14 09:27:42--  https://github.com/matthias-k/DeepGaze/releases/download/v1.0.0/centerbias_mit1003.npy\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/372933216/3c267f80-c32e-11eb-9f03-c6381f7da54a?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-14T10%3A03%3A50Z&rscd=attachment%3B+filename%3Dcenterbias_mit1003.npy&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-14T09%3A03%3A00Z&ske=2025-12-14T10%3A03%3A50Z&sks=b&skv=2018-11-09&sig=CfddLpr7sYFruZeSiwqh7ldIQJwwQCOOjGBokSKk8dY%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTcwNDc2MiwibmJmIjoxNzY1NzA0NDYyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.Mp4en0Fu8ywAbxUqEMt1dYT3z2o9Sz0dfmL79xgWdRU&response-content-disposition=attachment%3B%20filename%3Dcenterbias_mit1003.npy&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-14 09:27:42--  https://release-assets.githubusercontent.com/github-production-release-asset/372933216/3c267f80-c32e-11eb-9f03-c6381f7da54a?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-14T10%3A03%3A50Z&rscd=attachment%3B+filename%3Dcenterbias_mit1003.npy&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-14T09%3A03%3A00Z&ske=2025-12-14T10%3A03%3A50Z&sks=b&skv=2018-11-09&sig=CfddLpr7sYFruZeSiwqh7ldIQJwwQCOOjGBokSKk8dY%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTcwNDc2MiwibmJmIjoxNzY1NzA0NDYyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.Mp4en0Fu8ywAbxUqEMt1dYT3z2o9Sz0dfmL79xgWdRU&response-content-disposition=attachment%3B%20filename%3Dcenterbias_mit1003.npy&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8388688 (8.0M) [application/octet-stream]\n",
            "Saving to: â€˜/content/centerbias_mit1003.npyâ€™\n",
            "\n",
            "/content/centerbias 100%[===================>]   8.00M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-14 09:27:42 (70.8 MB/s) - â€˜/content/centerbias_mit1003.npyâ€™ saved [8388688/8388688]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O /content/centerbias_mit1003.npy \\\n",
        "  https://github.com/matthias-k/DeepGaze/releases/download/v1.0.0/centerbias_mit1003.npy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUboQF2lY8kj",
        "outputId": "a32ffdbb-7e6f-4022-cf4f-5ece6714a917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://bitbucket.org/robert_geirhos/texture-vs-shape-pretrained-models/raw/60b770e128fffcbd8562a3ab3546c1a735432d03/resnet50_finetune_60_epochs_lr_decay_after_30_start_resnet50_train_45_epochs_combined_IN_SF-ca06340c.pth.tar\" to /root/.cache/torch/hub/checkpoints/resnet50_finetune_60_epochs_lr_decay_after_30_start_resnet50_train_45_epochs_combined_IN_SF-ca06340c.pth.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195M/195M [00:11<00:00, 17.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b5-b6417697.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117M/117M [00:00<00:00, 214MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b5\n",
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.6.0\" to /root/.cache/torch/hub/v0.6.0.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /root/.cache/torch/hub/checkpoints/densenet201-c1103571.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.4M/77.4M [00:00<00:00, 165MB/s]\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95.8M/95.8M [00:00<00:00, 141MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/matthias-k/DeepGaze/releases/download/v1.0.0/deepgaze2e.pth\" to /root/.cache/torch/hub/checkpoints/deepgaze2e.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400M/400M [00:05<00:00, 77.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "import sys, cv2, torch, numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "from scipy.special import logsumexp\n",
        "\n",
        "if \"/content/DeepGaze/deepgaze_pytorch\" in sys.path:\n",
        "    sys.path.remove(\"/content/DeepGaze/deepgaze_pytorch\")\n",
        "if \"/content/DeepGaze\" not in sys.path:\n",
        "    sys.path.append(\"/content/DeepGaze\")      # ou deepgaze_pytorch selon ton clone\n",
        "import deepgaze_pytorch\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 1) Charger le modÃ¨le\n",
        "model_s = deepgaze_pytorch.DeepGazeIIE(pretrained=True).to(DEVICE).eval()\n",
        "\n",
        "# 2) Charger ton image (depuis OpenCV par ex.)\n",
        "image_bgr = cv2.imread(\"/content/test_bicycle.png\")\n",
        "def create_saillance(image_bgr):\n",
        "  image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "  H, W = image_rgb.shape[:2]\n",
        "\n",
        "  # 3) Charger le centerbias prÃ©-computÃ© et lâ€™adapter Ã  la taille de lâ€™image\n",
        "  centerbias_template = np.load(\"/content/centerbias_mit1003.npy\")   # 1024x1024\n",
        "  centerbias = zoom(\n",
        "      centerbias_template,\n",
        "      (H / centerbias_template.shape[0], W / centerbias_template.shape[1]),\n",
        "      order=0,\n",
        "      mode=\"nearest\",\n",
        "  )\n",
        "  # normaliser en log-densitÃ©\n",
        "  centerbias -= logsumexp(centerbias)\n",
        "\n",
        "  # 4) Convertir en tenseurs\n",
        "  image_tensor = torch.from_numpy(image_rgb.copy()).permute(2, 0, 1).float().unsqueeze(0).to(DEVICE)\n",
        "  # FIX: Removed one unsqueeze(0). The DeepGaze Finalizer expects centerbias as (Batch, Height, Width).\n",
        "  centerbias_tensor = torch.from_numpy(centerbias).unsqueeze(0).float().to(DEVICE)\n",
        "\n",
        "  # 5) PrÃ©dire la log-densitÃ© de saillance\n",
        "  with torch.no_grad():\n",
        "      log_density = model_s(image_tensor, centerbias_tensor)  # <-- ici on passe bien centerbias\n",
        "      saliency = log_density.exp()[0, 0].cpu().numpy()      # carte de saillance (H x W)\n",
        "  sal_norm = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
        "  sal_norm = (sal_norm * 255).astype(np.uint8)\n",
        "\n",
        "  # Convertir la heatmap en BGR avec colormap JET\n",
        "  heatmap = cv2.applyColorMap(sal_norm, cv2.COLORMAP_JET)\n",
        "\n",
        "  # Lire image originale au mÃªme format\n",
        "  orig = image_bgr # Use the already loaded image_bgr\n",
        "  orig = cv2.resize(orig, (saliency.shape[1], saliency.shape[0]))\n",
        "\n",
        "  # Fusion\n",
        "  overlay = cv2.addWeighted(orig, 0.6, heatmap, 0.4, 0)\n",
        "  final_overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
        "  return final_overlay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EmIXGIZOenxP",
        "outputId": "7c88dcc8-1dce-4865-af21-8dbd9d46b1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2893\n",
            "\n",
            "0: 384x640 2 bicycles, 2 cars, 324.4ms\n",
            "Speed: 15.9ms preprocess, 324.4ms inference, 43.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "frame : 1\n",
            "\n",
            "0: 384x640 2 bicycles, 2 cars, 147.3ms\n",
            "Speed: 8.3ms preprocess, 147.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "frame : 2\n",
            "Video processing finished.\n",
            "vÃ©lo regardÃ© pendant : 0.5\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(\"/content/eye_gaze_merged.mp4\")\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # ou 'XVID', 'avc1', etc.\n",
        "out = cv2.VideoWriter(\"/content/output.avi\", fourcc, fps, (width, height))\n",
        "\n",
        "\n",
        "start_frame = 2220\n",
        "with open(\"/content/datagaze.txt\", 'r') as f:\n",
        "    data = f.readlines()\n",
        "    f.close()\n",
        "x = np.zeros(int(len(data)/2))\n",
        "y = np.zeros(int(len(data)/2))\n",
        "for i in range(int(len(data)/2)):\n",
        "    data[i] = data[i][:-2]\n",
        "    x[i]= float(data[i].split(\";\")[0])\n",
        "    y[i]= float(data[i].split(\";\")[1])\n",
        "print(len(x))\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "count_bicycle = 0\n",
        "count = 0\n",
        "count_total = 0\n",
        "\n",
        "# Read the first frame outside the loop\n",
        "ret, frame = cap.read()\n",
        "\n",
        "while ret:\n",
        "    image = np.asarray(frame).copy() # Make a writable copy of the image array\n",
        "    results = model.predict(image)\n",
        "\n",
        "    image = create_saillance(image)\n",
        "    # Process detections in the current frame\n",
        "    for box in results[0].boxes.data:\n",
        "        # Check if the detected object is a bicycle (assuming class ID 1 for bicycle)\n",
        "        if int(box[5]) == 1:\n",
        "            # Extract bounding box coordinates from the current 'box'\n",
        "            x_min, y_min, x_max, y_max = box[:4].int().tolist()\n",
        "\n",
        "            # Check if gaze is within the bicycle's bounding box\n",
        "            # Ensure 'count' (index for x, y gaze data) does not exceed bounds of x, y arrays\n",
        "            if count < len(x) and x_min < x[count_total+start_frame] < x_max and y_min < y[count_total+start_frame] < y_max:\n",
        "                count_bicycle += 1\n",
        "            count += 1 # Increment count for each bicycle detected and processed for gaze\n",
        "\n",
        "            # Define the two points for the rectangle in the correct format (x, y)\n",
        "            pt1 = (x_min, y_min)\n",
        "            pt2 = (x_max, y_max)\n",
        "\n",
        "            cv2.rectangle(image, pt1, pt2, (255,0,0), 2)  # Draw rectangle\n",
        "\n",
        "    out.write(image)\n",
        "    count_total += 1\n",
        "    print(f\"frame : {count_total}\")\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    # Read the next frame at the end of the loop\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "# Release resources outside the loop\n",
        "out.release()\n",
        "cap.release()\n",
        "print(\"Video processing finished.\")\n",
        "\n",
        "# Avoid division by zero if no bicycles were processed\n",
        "if count > 0:\n",
        "    print(f\"vÃ©lo regardÃ© pendant : {count_bicycle / count}\")\n",
        "else:\n",
        "    print(\"No bicycles were detected or processed for gaze.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jivFM5eMeiVk"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/output.avi\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yquitT_D3d9Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}